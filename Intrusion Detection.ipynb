{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### wg 5 assignment\n",
    "# Anomaly Detection\n",
    "\n",
    "(This code brances off of committ 29821ccffaca5817b3fe0b3ae2d972f8132b7999.)\n",
    "\n",
    "(As an aside, I'm using python 3, not 2. Only change that had to be made was on the print statement at [*])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "header = pd.read_table(\"kddcup.names.txt\", header=None)\n",
    "att_types = pd.read_table(\"training_attack_types.txt\", sep=\" \", header=None)\n",
    "\n",
    "tr_raw = pd.read_csv(\"kddcup.data_10_percent_corrected\", header=None)\n",
    "test_raw = pd.read_csv(\"kddcup_testdata.corrected\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Do the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess(dat):\n",
    "    dat.columns = header[0]\n",
    "    att_types.columns = [\"attack\", \"type\"]\n",
    "    dat[\"type\"] = np.nan\n",
    "    for i in range(0, len(att_types[\"attack\"])):\n",
    "        dat.loc[dat[\"attack\"] == att_types.loc[i,].attack, \"type\"] = att_types.loc[i,].type\n",
    "    dat.type = dat.type.fillna(\"unlisted\")\n",
    "    dat.attack = dat.attack.astype('category')\n",
    "\n",
    "    dat[dat.select_dtypes(include=['number']).columns] = preprocessing.scale(\n",
    "        dat[dat.select_dtypes(include=['number']).columns])\n",
    "    dat = pd.get_dummies(dat, columns=['protocol_type', 'service', 'flag'])\n",
    "\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "tr = preprocess(tr_raw)\n",
    "test = preprocess(test_raw)  # actual test data (but labeled--don't cheat!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Prepare for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# not occurring in training set but occuring in test set so we just add it\n",
    "tr['service_icmp'] = 0\n",
    "test['service_red_i'] = 0\n",
    "test['service_urh_i'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tr_labels = tr[\"type\"].values\n",
    "tr_features = tr.drop([\"type\", \"attack\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_labels = test[\"type\"].values\n",
    "test_features = test.drop([\"type\", \"attack\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966704069395\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf.fit(tr_features, tr_labels)\n",
    "# TODO: is this correct? why don't we ever clf.predict(test_features)?\n",
    "print(clf.score(test_features, test_labels)) # [*]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## finding a better model\n",
    "We can automate algorithm selection and hyperparameter tuning. Auto-sklearn is a drop-in replacement of sci-kit learn that can do a lot of this (see for instance http://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small example from the documentation first\n",
    "(to get an idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import autosklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.cross_validation\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    sklearn.cross_validation.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are already timing task: index_run5\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/pynisher/limit_function_call.py\", line 83, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/evaluation/train_evaluator.py\", line 284, in eval_holdout\n",
      "    evaluator.fit_predict_and_loss(iterative=iterative)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/evaluation/train_evaluator.py\", line 77, in fit_predict_and_loss\n",
      "    i, train_indices=train_split, test_indices=test_split)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/evaluation/train_evaluator.py\", line 211, in _partial_fit_and_predict\n",
      "    self.Y_train[train_indices])\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/evaluation/abstract_evaluator.py\", line 340, in _fit_and_suppress_warnings\n",
      "    model.fit(X, y)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/pipeline/base.py\", line 88, in fit\n",
      "    X, fit_params = self.pre_transform(X, y, fit_params=fit_params)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/pipeline/classification.py\", line 102, in pre_transform\n",
      "    X, y, fit_params=fit_params)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/pipeline/base.py\", line 98, in pre_transform\n",
      "    X, fit_params = self._pre_transform(X, y, **fit_params)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/pipeline.py\", line 147, in _pre_transform\n",
      "    Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/pipeline/components/base.py\", line 379, in fit\n",
      "    return self.choice.fit(X, y, **kwargs)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/autosklearn/pipeline/components/feature_preprocessing/feature_agglomeration.py\", line 37, in fit\n",
      "    self.preprocessor.fit(X)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py\", line 874, in fit\n",
      "    return AgglomerativeClustering.fit(self, X.T, **params)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py\", line 765, in fit\n",
      "    **kwargs)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/externals/joblib/memory.py\", line 283, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py\", line 549, in _average_linkage\n",
      "    return linkage_tree(*args, **kwargs)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/sklearn/cluster/hierarchical.py\", line 430, in linkage_tree\n",
      "    out = hierarchy.linkage(X, method=linkage, metric=affinity)\n",
      "  File \"/home/valentin/anaconda2/envs/DS-CCMLWI-wg5/lib/python3.5/site-packages/scipy/cluster/hierarchy.py\", line 676, in linkage\n",
      "    raise ValueError(\"The condensed distance matrix must contain only finite values.\")\n",
      "ValueError: The condensed distance matrix must contain only finite values.\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n",
      "You are already timing task: index_run6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2017-03-22 18:00:46,313:intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2017-03-22 18:00:46,313:intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are already timing task: index_run6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2017-03-22 18:01:01,781:intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2017-03-22 18:01:01,781:intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.986666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Wow, this takes long! No wonder... (but default is to terminate after 60 minutes, see https://automl.github.io/auto-sklearn/stable/api.html)\n",
    "\n",
    "TODO: how big is that data set? Based on that, for how long do we have to expect our computation to take if it should go anywhere? How much time to allocate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### now back to our own task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "autoclf = autosklearn.classification.AutoSklearnClassifier()\n",
    "# the above line translates the following line to autosklearn:\n",
    "# clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n",
    "autoclf.fit(tr_features, tr_labels)\n",
    "# the above line translates the following line to autosklearn:\n",
    "# clf.fit(tr_features, tr_labels)\n",
    "y_hat_intdect = autoclf.predict(test_features)\n",
    "# the above line corresponds to nothing.\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(test_features, y_hat_intdect))\n",
    "# the above line translates the following line to autosklearn:\n",
    "# print(clf.score(test_features, test_labels)) # [*]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
